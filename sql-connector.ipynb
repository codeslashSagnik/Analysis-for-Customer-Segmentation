{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setConnection():\n",
    "    try:\n",
    "        load_dotenv()\n",
    "\n",
    "        # Retrieve MySQL connection details from environment variables\n",
    "        host = os.getenv('DB_HOST')\n",
    "        user = os.getenv('DB_USER')\n",
    "        password = os.getenv('DB_PASSWORD')\n",
    "        connection = mysql.connector.connect(\n",
    "            host='localhost',\n",
    "            user='root',\n",
    "            password='user',\n",
    "            autocommit=True  # Set autocommit to True\n",
    "        )\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED\") \n",
    "        return cursor, connection\n",
    "    except mysql.connector.Error as e:\n",
    "        print(e)\n",
    "        return None, None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDatabase(cursor, name):\n",
    "    try:\n",
    "        cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {name}\")\n",
    "        cursor.execute(f\"USE {name}\")  \n",
    "    except mysql.connector.Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTable(cursor, tablename, dataframe,databaseName):\n",
    "    try:\n",
    "        engine = create_engine(f\"mysql+mysqlconnector://root:user@localhost/{databaseName}\")\n",
    "        dataframe.to_sql(name=tablename, con=engine, if_exists='replace', index=False)\n",
    "        print(f\"Table '{tablename}' successfully installed in the database\")\n",
    "        cursor.execute(f\"DESCRIBE {tablename}\")\n",
    "        print(\"Table schema:\")\n",
    "        for column in cursor.fetchall():\n",
    "            print(column)\n",
    "    except mysql.connector.Error as mysql_error:\n",
    "        print(f\"MySQL Connector Error: {mysql_error}\")\n",
    "    except Exception as sqlalchemy_error:\n",
    "        print(f\"SQLAlchemy Error: {sqlalchemy_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(cursor,queryString):\n",
    "    try:\n",
    "        cursor.execute(queryString)\n",
    "        rows = cursor.fetchall()\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "    except mysql.connector.Error as e:\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeConnection(cursor,connection):\n",
    "    try:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    except mysql.connector.Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOading Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDatasetcsv(name, unwanted_columns, frame=None):\n",
    "    if frame is None:\n",
    "        frame = pd.read_csv(f'./data/{name}.csv')\n",
    "    else:\n",
    "        frame = frame.copy()  # Create a copy of the DataFrame to avoid modifying the original\n",
    "\n",
    "    # Drop unwanted columns\n",
    "    for column in unwanted_columns:\n",
    "        frame.drop(columns=[column], inplace=True)\n",
    "    \n",
    "    # Ensure frame is a DataFrame\n",
    "    if not isinstance(frame, pd.DataFrame):\n",
    "        frame = pd.DataFrame(frame)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Function to process salary string\n",
    "def process_salary(salary):\n",
    "    if '/yr' in salary:\n",
    "        # If salary is per year, remove '/yr' and convert to int\n",
    "        salary = int(salary.replace('₹', '').replace(',', '').replace('/yr', ''))\n",
    "    elif '/mo' in salary:\n",
    "        # If salary is per month, remove '/mo', convert to int, and convert to yearly salary\n",
    "        salary = int(salary.replace('₹', '').replace(',', '').replace('/mo', '')) * 12\n",
    "    return salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDatasetxl(name, unwanted_columns, frame=None):\n",
    "    if frame is None:\n",
    "        frame = pd.read_csv(f'./data/{name}.xls')\n",
    "    else:\n",
    "        frame = frame.copy()  # Create a copy of the DataFrame to avoid modifying the original\n",
    "\n",
    "    # Drop unwanted columns\n",
    "    for column in unwanted_columns:\n",
    "        frame.drop(columns=[column], inplace=True)\n",
    "    \n",
    "    # Ensure frame is a DataFrame\n",
    "    if not isinstance(frame, pd.DataFrame):\n",
    "        frame = pd.DataFrame(frame)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_columns = [] \n",
    "list_datasets=['Customer_Trans_RFM_Analysis','CustomerAddress','CustomerDemographics','NewCustomerList','Transactions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagnik\\AppData\\Local\\Temp\\ipykernel_12956\\3572659709.py:4: UserWarning: The provided table name 'Customer_Trans_RFM_Analysis' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  dataframe.to_sql(name=tablename, con=engine, if_exists='replace', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Customer_Trans_RFM_Analysis' successfully installed in the database\n",
      "Table schema:\n",
      "('transaction_id', 'bigint', 'YES', '', None, '')\n",
      "('product_id', 'bigint', 'YES', '', None, '')\n",
      "('customer_id', 'bigint', 'YES', '', None, '')\n",
      "('transaction_date', 'text', 'YES', '', None, '')\n",
      "('online_order', 'double', 'YES', '', None, '')\n",
      "('order_status', 'text', 'YES', '', None, '')\n",
      "('brand', 'text', 'YES', '', None, '')\n",
      "('product_line', 'text', 'YES', '', None, '')\n",
      "('product_class', 'text', 'YES', '', None, '')\n",
      "('product_size', 'text', 'YES', '', None, '')\n",
      "('list_price', 'double', 'YES', '', None, '')\n",
      "('standard_cost', 'double', 'YES', '', None, '')\n",
      "('product_first_sold_date', 'double', 'YES', '', None, '')\n",
      "('Profit', 'double', 'YES', '', None, '')\n",
      "('full_name', 'text', 'YES', '', None, '')\n",
      "('gender', 'text', 'YES', '', None, '')\n",
      "('past_3_years_bike_related_purchases', 'bigint', 'YES', '', None, '')\n",
      "('DOB', 'text', 'YES', '', None, '')\n",
      "('job_title', 'text', 'YES', '', None, '')\n",
      "('job_industry_category', 'text', 'YES', '', None, '')\n",
      "('wealth_segment', 'text', 'YES', '', None, '')\n",
      "('deceased_indicator', 'text', 'YES', '', None, '')\n",
      "('owns_car', 'text', 'YES', '', None, '')\n",
      "('tenure', 'double', 'YES', '', None, '')\n",
      "('Age', 'bigint', 'YES', '', None, '')\n",
      "('recency', 'bigint', 'YES', '', None, '')\n",
      "('frequency', 'bigint', 'YES', '', None, '')\n",
      "('monetary', 'double', 'YES', '', None, '')\n",
      "('r_quartile', 'bigint', 'YES', '', None, '')\n",
      "('f_quartile', 'bigint', 'YES', '', None, '')\n",
      "('m_quartile', 'bigint', 'YES', '', None, '')\n",
      "('rfm_score', 'bigint', 'YES', '', None, '')\n",
      "('customer_title', 'text', 'YES', '', None, '')\n",
      "('Age_Group', 'bigint', 'YES', '', None, '')\n",
      "('detail_cust_title', 'text', 'YES', '', None, '')\n",
      "('rank', 'bigint', 'YES', '', None, '')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagnik\\AppData\\Local\\Temp\\ipykernel_12956\\3572659709.py:4: UserWarning: The provided table name 'CustomerAddress' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  dataframe.to_sql(name=tablename, con=engine, if_exists='replace', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'CustomerAddress' successfully installed in the database\n",
      "Table schema:\n",
      "('customer_id', 'bigint', 'YES', '', None, '')\n",
      "('address', 'text', 'YES', '', None, '')\n",
      "('postcode', 'bigint', 'YES', '', None, '')\n",
      "('state', 'text', 'YES', '', None, '')\n",
      "('country', 'text', 'YES', '', None, '')\n",
      "('property_valuation', 'bigint', 'YES', '', None, '')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagnik\\AppData\\Local\\Temp\\ipykernel_12956\\3572659709.py:4: UserWarning: The provided table name 'CustomerDemographics' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  dataframe.to_sql(name=tablename, con=engine, if_exists='replace', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'CustomerDemographics' successfully installed in the database\n",
      "Table schema:\n",
      "('customer_id', 'bigint', 'YES', '', None, '')\n",
      "('full_name', 'text', 'YES', '', None, '')\n",
      "('gender', 'text', 'YES', '', None, '')\n",
      "('past_3_years_bike_related_purchases', 'bigint', 'YES', '', None, '')\n",
      "('DOB', 'text', 'YES', '', None, '')\n",
      "('job_title', 'text', 'YES', '', None, '')\n",
      "('job_industry_category', 'text', 'YES', '', None, '')\n",
      "('wealth_segment', 'text', 'YES', '', None, '')\n",
      "('deceased_indicator', 'text', 'YES', '', None, '')\n",
      "('owns_car', 'text', 'YES', '', None, '')\n",
      "('tenure', 'double', 'YES', '', None, '')\n",
      "('Age', 'bigint', 'YES', '', None, '')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagnik\\AppData\\Local\\Temp\\ipykernel_12956\\3572659709.py:4: UserWarning: The provided table name 'NewCustomerList' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  dataframe.to_sql(name=tablename, con=engine, if_exists='replace', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'NewCustomerList' successfully installed in the database\n",
      "Table schema:\n",
      "('gender', 'text', 'YES', '', None, '')\n",
      "('past_3_years_bike_related_purchases', 'bigint', 'YES', '', None, '')\n",
      "('DOB', 'text', 'YES', '', None, '')\n",
      "('job_title', 'text', 'YES', '', None, '')\n",
      "('job_industry_category', 'text', 'YES', '', None, '')\n",
      "('wealth_segment', 'text', 'YES', '', None, '')\n",
      "('deceased_indicator', 'text', 'YES', '', None, '')\n",
      "('owns_car', 'text', 'YES', '', None, '')\n",
      "('tenure', 'bigint', 'YES', '', None, '')\n",
      "('address', 'text', 'YES', '', None, '')\n",
      "('postcode', 'bigint', 'YES', '', None, '')\n",
      "('state', 'text', 'YES', '', None, '')\n",
      "('country', 'text', 'YES', '', None, '')\n",
      "('property_valuation', 'bigint', 'YES', '', None, '')\n",
      "('Rank', 'bigint', 'YES', '', None, '')\n",
      "('Value', 'double', 'YES', '', None, '')\n",
      "('full_name', 'text', 'YES', '', None, '')\n",
      "('Age', 'bigint', 'YES', '', None, '')\n",
      "('Age Group', 'bigint', 'YES', '', None, '')\n",
      "Table 'Transactions' successfully installed in the database\n",
      "Table schema:\n",
      "('transaction_id', 'bigint', 'YES', '', None, '')\n",
      "('product_id', 'bigint', 'YES', '', None, '')\n",
      "('customer_id', 'bigint', 'YES', '', None, '')\n",
      "('transaction_date', 'text', 'YES', '', None, '')\n",
      "('online_order', 'double', 'YES', '', None, '')\n",
      "('order_status', 'text', 'YES', '', None, '')\n",
      "('brand', 'text', 'YES', '', None, '')\n",
      "('product_line', 'text', 'YES', '', None, '')\n",
      "('product_class', 'text', 'YES', '', None, '')\n",
      "('product_size', 'text', 'YES', '', None, '')\n",
      "('list_price', 'double', 'YES', '', None, '')\n",
      "('standard_cost', 'double', 'YES', '', None, '')\n",
      "('product_first_sold_date', 'double', 'YES', '', None, '')\n",
      "('Profit', 'double', 'YES', '', None, '')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagnik\\AppData\\Local\\Temp\\ipykernel_12956\\3572659709.py:4: UserWarning: The provided table name 'Transactions' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  dataframe.to_sql(name=tablename, con=engine, if_exists='replace', index=False)\n"
     ]
    }
   ],
   "source": [
    "cursor, connection = setConnection()\n",
    "\n",
    "# Create database\n",
    "createDatabase(cursor, 'customer_segmentation_db')\n",
    "\n",
    "# Load and store datasets in the database\n",
    "for dataset_name in list_datasets:\n",
    "    dataset = loadDatasetcsv(dataset_name, unwanted_columns)\n",
    "    createTable(cursor, dataset_name,dataset,'customer_segmentation_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Column Names of Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Customer_Trans_RFM_Analysis': ['transaction_id', 'product_id', 'customer_id', 'transaction_date', 'online_order', 'order_status', 'brand', 'product_line', 'product_class', 'product_size', 'list_price', 'standard_cost', 'product_first_sold_date', 'Profit', 'full_name', 'gender', 'past_3_years_bike_related_purchases', 'DOB', 'job_title', 'job_industry_category', 'wealth_segment', 'deceased_indicator', 'owns_car', 'tenure', 'Age', 'recency', 'frequency', 'monetary', 'r_quartile', 'f_quartile', 'm_quartile', 'rfm_score', 'customer_title', 'Age_Group', 'detail_cust_title', 'rank'], 'CustomerAddress': ['customer_id', 'address', 'postcode', 'state', 'country', 'property_valuation'], 'CustomerDemographics': ['customer_id', 'full_name', 'gender', 'past_3_years_bike_related_purchases', 'DOB', 'job_title', 'job_industry_category', 'wealth_segment', 'deceased_indicator', 'owns_car', 'tenure', 'Age'], 'NewCustomerList': ['gender', 'past_3_years_bike_related_purchases', 'DOB', 'job_title', 'job_industry_category', 'wealth_segment', 'deceased_indicator', 'owns_car', 'tenure', 'address', 'postcode', 'state', 'country', 'property_valuation', 'Rank', 'Value', 'full_name', 'Age', 'Age Group'], 'Transactions': ['transaction_id', 'product_id', 'customer_id', 'transaction_date', 'online_order', 'order_status', 'brand', 'product_line', 'product_class', 'product_size', 'list_price', 'standard_cost', 'product_first_sold_date', 'Profit']}\n"
     ]
    }
   ],
   "source": [
    "tables = ['Customer_Trans_RFM_Analysis', 'CustomerAddress', 'CustomerDemographics', 'NewCustomerList', 'Transactions']\n",
    "\n",
    "# Dictionary to store column names for each table\n",
    "column_names_dict = {}\n",
    "\n",
    "# Iterate through tables and fetch column names\n",
    "for table in tables:\n",
    "    query_string = f\"SHOW COLUMNS FROM {table};\"\n",
    "    cursor.execute(query_string)\n",
    "    columns = cursor.fetchall()\n",
    "    column_names = [column[0] for column in columns]\n",
    "    column_names_dict[table] = column_names\n",
    "\n",
    "# Print the dictionary\n",
    "print(column_names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19542,)\n"
     ]
    }
   ],
   "source": [
    "query(cursor,\"SELECT COUNT(transaction_id) AS total_transactions FROM Customer_Trans_RFM_Analysis;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Profit per Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550.7695184457918,)\n"
     ]
    }
   ],
   "source": [
    "query(cursor,\"SELECT AVG(Profit) AS avg_profit_per_transaction FROM Customer_Trans_RFM_Analysis;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique customers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3416,)\n"
     ]
    }
   ],
   "source": [
    "query(cursor,\"SELECT COUNT(DISTINCT customer_id) AS unique_customers_count FROM Customer_Trans_RFM_Analysis;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The most frequently purchased product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1337)\n"
     ]
    }
   ],
   "source": [
    "query(cursor,\"SELECT product_id,  COUNT(*) AS purchase_count FROM Customer_Trans_RFM_Analysis GROUP BY product_id ORDER BY purchase_count DESC LIMIT 1;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177,)\n"
     ]
    }
   ],
   "source": [
    "query(cursor,\"SELECT COUNT(*) FROM customer_segmentation_db.customer_trans_rfm_analysis WHERE order_status != 'Approved';\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
